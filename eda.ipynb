{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>death_year</th>\n",
       "      <th>title</th>\n",
       "      <th>first_line</th>\n",
       "      <th>image_url</th>\n",
       "      <th>poem_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APH</td>\n",
       "      <td>Alexander Pope</td>\n",
       "      <td>1688</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>An Essay on Man: Epistle I</td>\n",
       "      <td>Hope springs eternal in the human breast:\\nMan...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>https://www.poetryfoundation.org/poems/44899/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT</td>\n",
       "      <td>Alfred Lord Tennyson</td>\n",
       "      <td>1809</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>In Memoriam A.H.H. 1849</td>\n",
       "      <td>The heart that never plighted troth\\n      But...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALT</td>\n",
       "      <td>Alfred Lord Tennyson</td>\n",
       "      <td>1809</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>In Memoriam, [Ring out, wild bells]</td>\n",
       "      <td>The year is dying in the night;\\nRing out, wil...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>https://poets.org/poem/memoriam-ring-out-wild-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RBU</td>\n",
       "      <td>Robert Burns</td>\n",
       "      <td>1759</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>Auld Lang Syne</td>\n",
       "      <td>Should auld acquaintance be forgot,\\nAnd never...</td>\n",
       "      <td>https://poets.org/sites/default/files/images/b...</td>\n",
       "      <td>https://poets.org/poem/auld-lang-syne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESR</td>\n",
       "      <td>Edna St. Vincent Millay</td>\n",
       "      <td>1892</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>Recuerdo</td>\n",
       "      <td>We were very tired, we were very merryâ€”\\nWe ha...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>https://www.poetryfoundation.org/poetrymagazin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LYL</td>\n",
       "      <td>Li-Young Lee</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Persimmons</td>\n",
       "      <td>In sixth grade Mrs. Walker\\nslapped the back o...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>WAM</td>\n",
       "      <td>W.H. Auden</td>\n",
       "      <td>1907</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>In Memory of W. B. Yeats</td>\n",
       "      <td>You were silly like us; your gift survived it ...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RHA</td>\n",
       "      <td>Robert Hayden</td>\n",
       "      <td>1913</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>Those Winter Sundays</td>\n",
       "      <td>Sundays too my father got up early\\nand put hi...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/4/4d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>THG</td>\n",
       "      <td>Ted Hughes</td>\n",
       "      <td>1930</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>The Thought-Fox</td>\n",
       "      <td>Across clearings, an eye,\\nA widening deepenin...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/thum...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DSM</td>\n",
       "      <td>Danez Smith</td>\n",
       "      <td>1989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dear white america</td>\n",
       "      <td>iâ€™ve left Earth in search of darker planets, a...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                     name  birth_year  death_year  \\\n",
       "0   APH           Alexander Pope        1688      1744.0   \n",
       "1    AT     Alfred Lord Tennyson        1809      1892.0   \n",
       "2   ALT     Alfred Lord Tennyson        1809      1892.0   \n",
       "3   RBU             Robert Burns        1759      1796.0   \n",
       "4   ESR  Edna St. Vincent Millay        1892      1950.0   \n",
       "..  ...                      ...         ...         ...   \n",
       "95  LYL             Li-Young Lee        1957         NaN   \n",
       "96  WAM               W.H. Auden        1907      1973.0   \n",
       "97  RHA            Robert Hayden        1913      1980.0   \n",
       "98  THG               Ted Hughes        1930      1998.0   \n",
       "99  DSM              Danez Smith        1989         NaN   \n",
       "\n",
       "                                  title  \\\n",
       "0            An Essay on Man: Epistle I   \n",
       "1               In Memoriam A.H.H. 1849   \n",
       "2   In Memoriam, [Ring out, wild bells]   \n",
       "3                        Auld Lang Syne   \n",
       "4                              Recuerdo   \n",
       "..                                  ...   \n",
       "95                           Persimmons   \n",
       "96             In Memory of W. B. Yeats   \n",
       "97                 Those Winter Sundays   \n",
       "98                      The Thought-Fox   \n",
       "99                   dear white america   \n",
       "\n",
       "                                           first_line  \\\n",
       "0   Hope springs eternal in the human breast:\\nMan...   \n",
       "1   The heart that never plighted troth\\n      But...   \n",
       "2   The year is dying in the night;\\nRing out, wil...   \n",
       "3   Should auld acquaintance be forgot,\\nAnd never...   \n",
       "4   We were very tired, we were very merryâ€”\\nWe ha...   \n",
       "..                                                ...   \n",
       "95  In sixth grade Mrs. Walker\\nslapped the back o...   \n",
       "96  You were silly like us; your gift survived it ...   \n",
       "97  Sundays too my father got up early\\nand put hi...   \n",
       "98  Across clearings, an eye,\\nA widening deepenin...   \n",
       "99  iâ€™ve left Earth in search of darker planets, a...   \n",
       "\n",
       "                                            image_url  \\\n",
       "0   https://upload.wikimedia.org/wikipedia/commons...   \n",
       "1   https://upload.wikimedia.org/wikipedia/commons...   \n",
       "2   https://upload.wikimedia.org/wikipedia/commons...   \n",
       "3   https://poets.org/sites/default/files/images/b...   \n",
       "4   https://upload.wikimedia.org/wikipedia/commons...   \n",
       "..                                                ...   \n",
       "95  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "96  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "97  https://upload.wikimedia.org/wikipedia/en/4/4d...   \n",
       "98  https://upload.wikimedia.org/wikipedia/en/thum...   \n",
       "99  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "\n",
       "                                            poem_link  \n",
       "0   https://www.poetryfoundation.org/poems/44899/a...  \n",
       "1                                                 NaN  \n",
       "2   https://poets.org/poem/memoriam-ring-out-wild-...  \n",
       "3               https://poets.org/poem/auld-lang-syne  \n",
       "4   https://www.poetryfoundation.org/poetrymagazin...  \n",
       "..                                                ...  \n",
       "95                                                NaN  \n",
       "96                                                NaN  \n",
       "97                                                NaN  \n",
       "98                                                NaN  \n",
       "99                                                NaN  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"authors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"authors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Hope springs eternal in the human breast:\\nMan...\n",
       "1     The heart that never plighted troth\\n      But...\n",
       "2     The year is dying in the night;\\nRing out, wil...\n",
       "3     Should auld acquaintance be forgot,\\nAnd never...\n",
       "4     We were very tired, we were very merryâ€”\\nWe ha...\n",
       "                            ...                        \n",
       "95    In sixth grade Mrs. Walker\\nslapped the back o...\n",
       "96    You were silly like us; your gift survived it ...\n",
       "97    Sundays too my father got up early\\nand put hi...\n",
       "98    Across clearings, an eye,\\nA widening deepenin...\n",
       "99    iâ€™ve left Earth in search of darker planets, a...\n",
       "Name: first_line, Length: 100, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['first_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Hope springs eternal in the human breast:\\nMan never is, but always to be blest:\\nThe soul, uneasy and confin'd from home,\\nRests and expatiates in a life to come.\\nLo! the poor Indian, whose untutor'd mind\\nSees God in clouds, or hears him in the wind;\\nHis soul, proud science never taught to stray\\nFar as the solar walk, or milky way;\n",
       "1                                                                                      The heart that never plighted troth\\n      But stagnates in the weeds of sloth,\\nNor any want-begotten rest.\\nI hold it true, whateâ€™er befall,\\n      I feel it, when I sorrow most;\\n      â€˜Tis better to have loved and lost\\nThan never to have loved at all.\n",
       "2                                                                                                                       The year is dying in the night;\\nRing out, wild bells, and let him die.\\n\\nRing out the old, ring in the new,\\n   Ring, happy bells, across the snow:\\n   The year is going, let him go;\\nRing out the false, ring in the true.\n",
       "Name: first_line, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['first_line'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                       ([breast:, blest:, home,, come., mind, wind;, stray, way;], [[molest:, infest:, unaddressed:, attest:, impressed:], [infest:, detest:, prest:, natwest:, confessed:], [strome,, shalom,, gloam,, noam,, boehm,], [humm., thum., dum., pflum., alum.], [blind, undermined, fined, defined, unkind], [resigned;, mankind;, disinclined;, reclined;, twined;], [monterey, seay, convey, pei, deseret], [voisey;, gai;, monet;, dekay;, attache;]])\n",
       "1                                                                                                                                                                                                                                                                                                                       ([troth, sloth,, rest., befall,, most;, lost, all.], [[quoth, goethe, old-growth, both, growth], [goethe,, oath,, both,, troth,, quoth,], [bequest., southwest., blessed., compressed., confessed.], [crawl,, mcnall,, fall,, sprawl,, gall,], [voest;, khost;, engrossed;, roast;, diagnosed;], [lacoste, crossed, maust, low-cost, embossed], [dall., vantol., luminol., montreal., brawl.]])\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                               ([night;, die., new,, snow:, go;, true.], [[brite;, bite;, dunite;, kyte;, tonite;], [good-bye., kyi., shy., cspi., lai.], [shampoo,, gnu,, leroux,, renew,, khuu,], [drapeau:, taekwondo:, co.:, cabo:, beaux:], [hello;, daignault;, clow;, cau;, pernod;], [edu., hewe., ballyhoo., mcknew., cpu.]])\n",
       "3                                                                                                                                                                                                                                                                                                                      ([forgot,, mind?, forgot,, syne!, Chorus:, dear,, syne., yet,, syne.], [[schlott,, voght,, notte,, konsultat,, caught,], [wined?, hind?, declined?, dined?, inclined?], [jot,, mott,, yacht,, montserrat,, demott,], [], [Morris':, Brontosaurus:, Mcmorris:, Horace:, Goris:], [chevalier,, smear,, premier,, appear,, pelletier,], [], [marette,, bourret,, janette,, lafeyette,, duet,], []])\n",
       "4                                                                                                                                                                                                                                                                                                                                                                         ([merryâ€”, ferry;, pear,, somewhere;, cold,, gold.], [[cherryâ€”, eyrieâ€”, mccaryâ€”, larryâ€”, barryâ€”], [canzoneri;, barre;, nary;, metairie;, gery;], [kreher,, bahr,, altair,, sterr,, there,], [grancare;, glassware;, alastair;, bakeware;, cookware;], [remold,, fourfold,, roald,, bold,, sold,], [patrolled., vold., scold., told., holde.]])\n",
       "                                                                                                                                                                                                                                                                                                                                                            ...                                                                                                                                                                                                                                                                                                                                                        \n",
       "95                                                                                                                                                                                                                                                                                                                            ([Walker, head, corner, difference, precision., choose, precision.], [[Chalker, Stalker, Talker, Auker, Hawker], [fled, biomed, interbred, overfed, abed], [hoerner, forner, horner, swarner, dorner], [indifference], [envision., incision., parisian., collision., indecision.], [pews, sues, druse, chartreuse, yew's], [recision., collision., univision., excision., multivision.]])\n",
       "96                                                                                                                                                                                                                                                          ([all:, decay,, poetry., still,, survives, executives, south, griefs,, survives,, mouth.], [[engwall:, paul:, mccall:, small:, taul:], [hay,, waga,, ceta,, rene,, moray,], [], [kill,, we'll,, fill,, bill,, instill,], [strives, hives, arrives, revives, fives], [executive's, executives'], [mouth, foot-and-mouth, louth, strouth, routh], [], [arrives,, rives,, deprives,, lives',, derives,], [routh., foot-and-mouth., strouth., louth., south.]])\n",
       "97    ([early, cold,, ached, made, him., breaking., call,, dress,, house,, him,, cold, well., know, offices?], [[curley, burley, gurley, pearly, akerley], [unrolled,, machold,, doled,, strolled,, controlled,], [baked, raked, faked, caked, staked], [evade, allayed, conveyed, spayde, buffeted], [tim., primm., krim., patronym., prelim.], [staking., quaking., baking., making., raking.], [hall,, raul,, rall,, wal,, mccaul,], [attests,, bess,, aggress,, tess,, ccs,], [in-house,, krouse,, strauss,, strause,, bouse,], [zim,, sim,, timme,, prelim,, kibbutzim,], [controlled, undersold, extolled, oversold, holed], [roussel., joelle., bell., kjell., shell.], [gloe, tarot, bleau, rohe, y'know], []])\n",
       "98                                                                                                                                                                                                                                                                                                                                             ([eye,, greenness,, concentratedly,, business, fox, head., ticks,, printed.], [[spy,, kansai,, tie,, altai,, spry,], [meanness,], [], [business', non-business, nonbusiness], [rocks, block's, brock's, iraq's, ochs], [biomed., shed., tread., dead., thread.], [transfix,, slicks,, predicts,, sticks,, hicks,], [minted., reprinted., tinted., hinted., imprinted.]])\n",
       "99                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ([near, you, she, used, beautiful,, want], [[vanleer, minteer, queer, gondolier, fier], [depue, loo, schou, coutu, zue], [b.c., vee, nbc, zea, childree], [fused, accused, defused, amused, recused], [], [kvant, vermont, fonte, font, enfant]])\n",
       "Name: first_line, Length: 100, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['first_line'].apply(get_rhymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/melwalsh/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"brown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/melwalsh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import pronouncing\n",
    "from nltk.corpus import brown\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "random.seed(42)  # reproducible builds\n",
    "\n",
    "\n",
    "# --------- CONFIG ---------\n",
    "MIN_FREQ = 50  # ðŸ‘ˆ raise/lower this as you like for \"common\" words\n",
    "\n",
    "\n",
    "# --------- helpers for cores, POS & frequency ---------\n",
    "def word_core_lower(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Very forgiving core extractor for duplicate checks:\n",
    "    - takes the first run of letters/apostrophes\n",
    "    - lowercases it\n",
    "    So 'breast:', 'Breast', '\"breast:\"' -> 'breast'\n",
    "    \"\"\"\n",
    "    m = re.search(r\"[A-Za-z']+\", word)\n",
    "    if m:\n",
    "        return m.group(0).lower()\n",
    "    return word.lower()\n",
    "\n",
    "\n",
    "# Build a frequency counter over the Brown corpus\n",
    "word_freq = Counter(w.lower() for w in brown.words())\n",
    "\n",
    "def is_common_word(word: str, min_frequency: int = MIN_FREQ) -> bool:\n",
    "    \"\"\"\n",
    "    Check if word appears frequently enough in common English,\n",
    "    using the Brown corpus as a rough filter.\n",
    "    Also require the core to be at least 3 letters long.\n",
    "    \"\"\"\n",
    "    core = word_core_lower(word)\n",
    "    if len(core) < 3:\n",
    "        return False\n",
    "    return word_freq.get(core, 0) >= min_frequency\n",
    "\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    \"\"\"Make a URL / id-friendly slug from a string.\"\"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^\\w\\s-]\", \"\", s)  # remove punctuation\n",
    "    s = re.sub(r\"\\s+\", \"-\", s).strip(\"-\")  # spaces -> hyphens\n",
    "    return s\n",
    "\n",
    "\n",
    "def split_core_and_punct(word: str):\n",
    "    \"\"\"\n",
    "    Split token into alphabetic core + trailing punctuation.\n",
    "    Examples:\n",
    "        'night,'    -> ('night', ',')\n",
    "        'Sea!'      -> ('Sea', '!')\n",
    "        'breast:'   -> ('breast', ':')\n",
    "        '\"time.\"'   -> ('time', '.\"')\n",
    "    \"\"\"\n",
    "    word = word.strip()\n",
    "    m = re.match(r\"^([A-Za-z']+)([^A-Za-z']*)$\", word)\n",
    "    if m:\n",
    "        return m.group(1), m.group(2)\n",
    "    else:\n",
    "        return word, \"\"\n",
    "\n",
    "\n",
    "def coarse_pos(tag: str) -> str:\n",
    "    \"\"\"\n",
    "    Map a fine-grained Penn Treebank POS tag to a coarse tag.\n",
    "    \"\"\"\n",
    "    if tag.startswith(\"N\"):\n",
    "        return \"NOUN\"\n",
    "    if tag.startswith(\"V\"):\n",
    "        return \"VERB\"\n",
    "    if tag.startswith(\"J\"):\n",
    "        return \"ADJ\"\n",
    "    if tag.startswith(\"R\"):\n",
    "        return \"ADV\"\n",
    "    return \"OTHER\"\n",
    "\n",
    "\n",
    "def get_coarse_pos(word: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Get a coarse POS tag for a single word using NLTK's pos_tag.\n",
    "    Returns None if tagging fails.\n",
    "    \"\"\"\n",
    "    core = word_core_lower(word)\n",
    "    if not core:\n",
    "        return None\n",
    "    try:\n",
    "        tag = pos_tag([core])[0][1]\n",
    "        return coarse_pos(tag)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# --------- rhyme distractors ---------\n",
    "def rhyme_distractors(core: str,\n",
    "                      punct: str,\n",
    "                      forbidden_core_set=None,\n",
    "                      max_distractors: int = 5,\n",
    "                      target_pos: str | None = None):\n",
    "    \"\"\"\n",
    "    Returns up to max_distractors rhyming words (no correct answer),\n",
    "    with punctuation reattached, excluding:\n",
    "\n",
    "      - any whose *core* is in forbidden_core_set (existing poem words)\n",
    "      - uncommon words (by Brown corpus frequency)\n",
    "      - words with non-letter/quote characters (no 'est.', 'p', 'z.' etc.)\n",
    "      - words whose coarse POS != target_pos (if target_pos is given)\n",
    "      - (optionally) words with different syllable count\n",
    "\n",
    "    Uses phones_for_word + rhyming_part + search() for nicer matches\n",
    "    tied to a specific pronunciation.\n",
    "    \"\"\"\n",
    "    if not core:\n",
    "        return []\n",
    "\n",
    "    if forbidden_core_set is None:\n",
    "        forbidden_core_set = set()\n",
    "\n",
    "    # 1) Get pronunciations for the core word\n",
    "    phones_list = pronouncing.phones_for_word(core.lower())\n",
    "    if not phones_list:\n",
    "        return []\n",
    "\n",
    "    phones = phones_list[0]\n",
    "\n",
    "    # 2) Get syllable count for the core word\n",
    "    try:\n",
    "        core_syllables = pronouncing.syllable_count(phones)\n",
    "    except Exception:\n",
    "        core_syllables = None\n",
    "\n",
    "    # 3) Get rhyme pattern and search for rhyming words\n",
    "    rhyme_pat = pronouncing.rhyming_part(phones)\n",
    "    candidates = pronouncing.search(rhyme_pat + \"$\")\n",
    "\n",
    "    # Fallback to simple rhymes() if search gives nothing\n",
    "    if not candidates:\n",
    "        candidates = pronouncing.rhymes(core.lower())\n",
    "\n",
    "    cleaned = []\n",
    "    for w in candidates:\n",
    "        lw_core = word_core_lower(w)\n",
    "\n",
    "        # --- basic shape / cleanliness filters ---\n",
    "        # must be at least 3 letters in core\n",
    "        if len(lw_core) < 3:\n",
    "            continue\n",
    "\n",
    "        # candidate itself must be purely letters / apostrophes\n",
    "        if not re.fullmatch(r\"[A-Za-z']+\", w):\n",
    "            continue\n",
    "\n",
    "        # skip if already in poem\n",
    "        if lw_core in forbidden_core_set:\n",
    "            continue\n",
    "\n",
    "        # skip uncommon words based on Brown corpus\n",
    "        if not is_common_word(w, min_frequency=MIN_FREQ):\n",
    "            continue\n",
    "\n",
    "        # POS filter: must match coarse POS of target word (if provided)\n",
    "        if target_pos is not None:\n",
    "            cand_pos = get_coarse_pos(w)\n",
    "            if cand_pos is None or cand_pos != target_pos:\n",
    "                continue\n",
    "\n",
    "        # optional: require same syllable count\n",
    "        if core_syllables is not None:\n",
    "            w_phones = pronouncing.phones_for_word(w.lower())\n",
    "            if not w_phones:\n",
    "                continue\n",
    "            if pronouncing.syllable_count(w_phones[0]) != core_syllables:\n",
    "                continue\n",
    "\n",
    "        cleaned.append(w)\n",
    "\n",
    "    # match capitalization pattern of original core\n",
    "    if core.istitle():\n",
    "        cleaned = [w.title() for w in cleaned]\n",
    "\n",
    "    # reattach punctuation from the original last word\n",
    "    cleaned = [w + punct for w in cleaned]\n",
    "\n",
    "    random.shuffle(cleaned)\n",
    "    return cleaned[:max_distractors]\n",
    "\n",
    "\n",
    "# --------- main pipeline ---------\n",
    "def build_line_level_game_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Input df must have columns (your current setup):\n",
    "        - name       (author name)\n",
    "        - title      (poem title)\n",
    "        - poem_link\n",
    "        - first_line (using this as poem text for now; can switch to poem_text later)\n",
    "\n",
    "    Output: line-level dataframe with columns:\n",
    "        poem_slug, author_name, poem_title, poem_link,\n",
    "        line_index, line_text,\n",
    "        correct_last_word, choice_1..choice_6, no_choices\n",
    "    \"\"\"\n",
    "    game_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        poem_text = row.get(\"first_line\")\n",
    "        if not isinstance(poem_text, str) or not poem_text.strip():\n",
    "            continue  # skip missing/empty\n",
    "\n",
    "        author_name = row.get(\"name\", \"\")\n",
    "        poem_title = row[\"title\"]\n",
    "        poem_link = row[\"poem_link\"]\n",
    "\n",
    "        poem_slug = slugify(f\"{author_name}-{poem_title}\")\n",
    "\n",
    "        # split into non-empty lines\n",
    "        lines = [ln for ln in poem_text.split(\"\\n\") if ln.strip()]\n",
    "\n",
    "        # ---- all word cores in this poem (forbidden for distractors) ----\n",
    "        forbidden_cores = set()\n",
    "        for ln in lines:\n",
    "            for tok in ln.split():\n",
    "                forbidden_cores.add(word_core_lower(tok))\n",
    "\n",
    "        for line_index, line in enumerate(lines):\n",
    "            tokens = line.split()\n",
    "            if not tokens:\n",
    "                continue\n",
    "\n",
    "            last_word_raw = tokens[-1]\n",
    "            core, punct = split_core_and_punct(last_word_raw)\n",
    "\n",
    "            # POS of the correct word (by core)\n",
    "            target_pos = get_coarse_pos(core)\n",
    "\n",
    "            # get up to 5 rhyming distractors with same POS\n",
    "            distractors = rhyme_distractors(\n",
    "                core,\n",
    "                punct,\n",
    "                forbidden_core_set=forbidden_cores,\n",
    "                max_distractors=5,\n",
    "                target_pos=target_pos,\n",
    "            )\n",
    "\n",
    "            correct_last_word = last_word_raw  # keep original incl. punctuation\n",
    "            correct_core_l = word_core_lower(correct_last_word)\n",
    "\n",
    "            # ---------- HARD NO-DUPLICATE GUARD (core-based) ----------\n",
    "            unique_distractors = []\n",
    "            seen_cores = {correct_core_l}  # start with correct word's core\n",
    "\n",
    "            for d in distractors:\n",
    "                d_core_l = word_core_lower(d)\n",
    "                if d_core_l in seen_cores:\n",
    "                    continue\n",
    "                seen_cores.add(d_core_l)\n",
    "                unique_distractors.append(d)\n",
    "\n",
    "            distractors = unique_distractors\n",
    "            # ----------------------------------------------------------\n",
    "\n",
    "            # If there are no distractors at all, keep the line but mark no_choices\n",
    "            if len(distractors) == 0:\n",
    "                options = [\"\", \"\", \"\", \"\", \"\", \"\"]  # all blanks for frontend\n",
    "                no_choices = True\n",
    "            else:\n",
    "                # normal case: correct + distractors\n",
    "                options = [correct_last_word] + distractors\n",
    "                random.shuffle(options)\n",
    "                # pad to exactly 6 options\n",
    "                while len(options) < 6:\n",
    "                    options.append(\"\")\n",
    "                no_choices = False\n",
    "\n",
    "            game_rows.append({\n",
    "                \"poem_slug\": poem_slug,\n",
    "                \"author_name\": author_name,\n",
    "                \"poem_title\": poem_title,\n",
    "                \"poem_link\": poem_link,\n",
    "                \"line_index\": line_index,\n",
    "                \"line_text\": line,\n",
    "                \"correct_last_word\": correct_last_word,\n",
    "                \"choice_1\": options[0],\n",
    "                \"choice_2\": options[1],\n",
    "                \"choice_3\": options[2],\n",
    "                \"choice_4\": options[3],\n",
    "                \"choice_5\": options[4],\n",
    "                \"choice_6\": options[5],\n",
    "                \"no_choices\": no_choices,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(game_rows)\n",
    "\n",
    "\n",
    "# --------- example usage ---------\n",
    "# import nltk\n",
    "# nltk.download(\"brown\")\n",
    "# nltk.download(\"averaged_perceptron_tagger\")  # or 'averaged_perceptron_tagger_eng'\n",
    "# df = pd.read_csv(\"poems_with_text.csv\")\n",
    "game_df = build_line_level_game_df(df)\n",
    "game_df.to_csv(\"poem_rhyme_game.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/melwalsh/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/melwalsh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/melwalsh/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# depending on your NLTK version, one of these will work:\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import pronouncing\n",
    "\n",
    "from nltk.corpus import brown, wordnet as wn\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "MIN_FREQ = 5                 # common word threshold (Brown)\n",
    "ENFORCE_POS = True            # turn off if too strict\n",
    "ENFORCE_WORDNET_VERB = False   # extra guardrail for verbs only\n",
    "MAX_DISTRACTORS = 5           # +1 correct = 6 total choices\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "# --------- frequency helpers ---------\n",
    "def word_core_lower(word: str) -> str:\n",
    "    m = re.search(r\"[A-Za-z']+\", word)\n",
    "    if m:\n",
    "        return m.group(0).lower()\n",
    "    return word.lower()\n",
    "\n",
    "\n",
    "word_freq = Counter(w.lower() for w in brown.words())\n",
    "\n",
    "def is_common_word(word: str, min_frequency: int = MIN_FREQ) -> bool:\n",
    "    core = word_core_lower(word)\n",
    "    if len(core) < 3:\n",
    "        return False\n",
    "    return word_freq.get(core, 0) >= min_frequency\n",
    "\n",
    "\n",
    "# --------- POS helpers ---------\n",
    "def coarse_pos(tag: str):\n",
    "    if tag.startswith(\"N\"):\n",
    "        return \"NOUN\"\n",
    "    if tag.startswith(\"V\"):\n",
    "        return \"VERB\"\n",
    "    if tag.startswith(\"J\"):\n",
    "        return \"ADJ\"\n",
    "    if tag.startswith(\"R\"):\n",
    "        return \"ADV\"\n",
    "    return \"OTHER\"\n",
    "\n",
    "\n",
    "def get_last_word_pos_from_line(line: str):\n",
    "    \"\"\"\n",
    "    Tag the last alphabetic word in the line using a simple regex tokenizer.\n",
    "    Avoids tagging punctuation like ':' as the last 'word'.\n",
    "    \"\"\"\n",
    "    # grab only \"word-like\" tokens (letters/apostrophes)\n",
    "    tokens = re.findall(r\"[A-Za-z']+\", line)\n",
    "    if not tokens:\n",
    "        return None\n",
    "\n",
    "    # tag in context: pos_tag uses the whole sequence\n",
    "    tagged = pos_tag(tokens)\n",
    "    last_tag = tagged[-1][1]\n",
    "    return coarse_pos(last_tag)\n",
    "\n",
    "\n",
    "\n",
    "def has_wordnet_verb_sense(word: str) -> bool:\n",
    "    return any(s.pos() == 'v' for s in wn.synsets(word_core_lower(word)))\n",
    "\n",
    "\n",
    "# --------- misc helpers ---------\n",
    "def slugify(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^\\w\\s-]\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \"-\", s).strip(\"-\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def split_core_and_punct(word: str):\n",
    "    word = word.strip()\n",
    "    m = re.match(r\"^([A-Za-z']+)([^A-Za-z']*)$\", word)\n",
    "    if m:\n",
    "        return m.group(1), m.group(2)\n",
    "    return word, \"\"\n",
    "\n",
    "\n",
    "# --------- rhyme distractors ----------\n",
    "def rhyme_distractors(core: str,\n",
    "                      punct: str,\n",
    "                      target_pos: str,\n",
    "                      forbidden_core_set=None,\n",
    "                      max_distractors: int = MAX_DISTRACTORS):\n",
    "\n",
    "    if not core:\n",
    "        return []\n",
    "\n",
    "    if forbidden_core_set is None:\n",
    "        forbidden_core_set = set()\n",
    "\n",
    "    phones_list = pronouncing.phones_for_word(core.lower())\n",
    "    if not phones_list:\n",
    "        return []\n",
    "\n",
    "    phones = phones_list[0]\n",
    "\n",
    "    # syllables of the correct answer\n",
    "    try:\n",
    "        core_syllables = pronouncing.syllable_count(phones)\n",
    "    except Exception:\n",
    "        core_syllables = None\n",
    "\n",
    "    rhyme_pat = pronouncing.rhyming_part(phones)\n",
    "    candidates = pronouncing.search(rhyme_pat + \"$\")\n",
    "\n",
    "    if not candidates:\n",
    "        candidates = pronouncing.rhymes(core.lower())\n",
    "\n",
    "    filtered = []\n",
    "\n",
    "    for w in candidates:\n",
    "        lw_core = word_core_lower(w)\n",
    "\n",
    "        # letters-only\n",
    "        if not re.fullmatch(r\"[A-Za-z']+\", w):\n",
    "            continue\n",
    "\n",
    "        # length reasonable\n",
    "        if len(lw_core) < 3:\n",
    "            continue\n",
    "\n",
    "        # not already in poem\n",
    "        if lw_core in forbidden_core_set:\n",
    "            continue\n",
    "\n",
    "        # common word\n",
    "        if not is_common_word(w):\n",
    "            continue\n",
    "\n",
    "        # match syllable count\n",
    "        if core_syllables is not None:\n",
    "            wp = pronouncing.phones_for_word(w.lower())\n",
    "            if not wp:\n",
    "                continue\n",
    "            if pronouncing.syllable_count(wp[0]) != core_syllables:\n",
    "                continue\n",
    "\n",
    "        # ---------- POS ENFORCEMENT ----------\n",
    "        if ENFORCE_POS and target_pos is not None:\n",
    "            tagged = pos_tag([w])\n",
    "            cand_pos = coarse_pos(tagged[0][1])\n",
    "\n",
    "            # keep only same coarse POS\n",
    "            if cand_pos != target_pos:\n",
    "                continue\n",
    "\n",
    "        # extra verb sanity check\n",
    "        if ENFORCE_WORDNET_VERB and target_pos == \"VERB\":\n",
    "            if not has_wordnet_verb_sense(w):\n",
    "                continue\n",
    "\n",
    "        filtered.append(w)\n",
    "\n",
    "    # match capitalization\n",
    "    if core.istitle():\n",
    "        filtered = [w.title() for w in filtered]\n",
    "\n",
    "    filtered = [w + punct for w in filtered]\n",
    "\n",
    "    random.shuffle(filtered)\n",
    "    return filtered[:max_distractors]\n",
    "\n",
    "\n",
    "# -------- MAIN PIPELINE ---------\n",
    "def build_line_level_game_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    game_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        poem_text = row.get(\"first_line\")\n",
    "        if not isinstance(poem_text, str) or not poem_text.strip():\n",
    "            continue\n",
    "\n",
    "        author_name = row.get(\"name\", \"\")\n",
    "        poem_title = row[\"title\"]\n",
    "        poem_link = row[\"poem_link\"]\n",
    "\n",
    "        poem_slug = slugify(f\"{author_name}-{poem_title}\")\n",
    "\n",
    "        lines = [ln for ln in poem_text.split(\"\\n\") if ln.strip()]\n",
    "\n",
    "        # words already in poem\n",
    "        forbidden_cores = set()\n",
    "        for ln in lines:\n",
    "            for tok in ln.split():\n",
    "                forbidden_cores.add(word_core_lower(tok))\n",
    "\n",
    "        for line_index, line in enumerate(lines):\n",
    "\n",
    "            tokens = line.split()\n",
    "            if not tokens:\n",
    "                continue\n",
    "\n",
    "            last_word_raw = tokens[-1]\n",
    "            core, punct = split_core_and_punct(last_word_raw)\n",
    "\n",
    "            # POS in context (important)\n",
    "            target_pos = get_last_word_pos_from_line(line)\n",
    "\n",
    "            distractors = rhyme_distractors(\n",
    "                core=core,\n",
    "                punct=punct,\n",
    "                target_pos=target_pos,\n",
    "                forbidden_core_set=forbidden_cores,\n",
    "                max_distractors=MAX_DISTRACTORS,\n",
    "            )\n",
    "\n",
    "            correct_last_word = last_word_raw\n",
    "\n",
    "            # remove accidental duplicates\n",
    "            seen = {word_core_lower(correct_last_word)}\n",
    "            unique = []\n",
    "            for d in distractors:\n",
    "                dc = word_core_lower(d)\n",
    "                if dc in seen:\n",
    "                    continue\n",
    "                seen.add(dc)\n",
    "                unique.append(d)\n",
    "\n",
    "            distractors = unique\n",
    "\n",
    "            if len(distractors) == 0:\n",
    "                options = [\"\"] * 6\n",
    "                no_choices = True\n",
    "            else:\n",
    "                options = [correct_last_word] + distractors\n",
    "                random.shuffle(options)\n",
    "                while len(options) < 6:\n",
    "                    options.append(\"\")\n",
    "                no_choices = False\n",
    "\n",
    "            game_rows.append({\n",
    "                \"poem_slug\": poem_slug,\n",
    "                \"author_name\": author_name,\n",
    "                \"poem_title\": poem_title,\n",
    "                \"poem_link\": poem_link,\n",
    "                \"line_index\": line_index,\n",
    "                \"line_text\": line,\n",
    "                \"correct_last_word\": correct_last_word,\n",
    "                \"choice_1\": options[0],\n",
    "                \"choice_2\": options[1],\n",
    "                \"choice_3\": options[2],\n",
    "                \"choice_4\": options[3],\n",
    "                \"choice_5\": options[4],\n",
    "                \"choice_6\": options[5],\n",
    "                \"no_choices\": no_choices,\n",
    "                \"target_pos\": target_pos,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(game_rows)\n",
    "\n",
    "\n",
    "# -------- run it --------\n",
    "# import nltk\n",
    "# nltk.download(\"brown\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "# nltk.download(\"wordnet\")\n",
    "\n",
    "# df = pd.read_csv(\"poems_with_text.csv\")\n",
    "game_df = build_line_level_game_df(df)\n",
    "game_df.to_csv(\"poem_rhyme_game.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/melwalsh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/melwalsh/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")  # only if error mentions punkt_tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import pronouncing\n",
    "\n",
    "random.seed(42)  # reproducible builds\n",
    "\n",
    "\n",
    "# --------- helpers ---------\n",
    "def slugify(s: str) -> str:\n",
    "    \"\"\"Make a URL / id-friendly slug from a string.\"\"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^\\w\\s-]\", \"\", s)  # remove punctuation\n",
    "    s = re.sub(r\"\\s+\", \"-\", s).strip(\"-\")  # spaces -> hyphens\n",
    "    return s\n",
    "\n",
    "\n",
    "def split_core_and_punct(word: str):\n",
    "    \"\"\"\n",
    "    Split token into alphabetic core + trailing punctuation.\n",
    "    Examples:\n",
    "        'night,'    -> ('night', ',')\n",
    "        'Sea!'      -> ('Sea', '!')\n",
    "        'breast:'   -> ('breast', ':')\n",
    "        '\"time.\"'   -> ('time', '.\"')\n",
    "    \"\"\"\n",
    "    word = word.strip()\n",
    "    m = re.match(r\"^([A-Za-z']+)([^A-Za-z']*)$\", word)\n",
    "    if m:\n",
    "        return m.group(1), m.group(2)\n",
    "    else:\n",
    "        return word, \"\"\n",
    "\n",
    "\n",
    "def word_core_lower(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Very forgiving core extractor for duplicate checks:\n",
    "    - takes the first run of letters/apostrophes\n",
    "    - lowercases it\n",
    "    So 'breast:', 'Breast', '\"breast:\"' -> 'breast'\n",
    "    \"\"\"\n",
    "    m = re.search(r\"[A-Za-z']+\", word)\n",
    "    if m:\n",
    "        return m.group(0).lower()\n",
    "    return word.lower()\n",
    "\n",
    "\n",
    "def rhyme_distractors(core: str,\n",
    "                      punct: str,\n",
    "                      forbidden_core_set=None,\n",
    "                      max_distractors: int = 5):\n",
    "    \"\"\"\n",
    "    Returns up to max_distractors rhyming words (no correct answer),\n",
    "    with punctuation reattached, excluding:\n",
    "\n",
    "      - any whose *core* is in forbidden_core_set (e.g. existing words in poem)\n",
    "\n",
    "    Uses phones_for_word + rhyming_part + search() for nicer matches\n",
    "    tied to a specific pronunciation.\n",
    "    \"\"\"\n",
    "    if not core:\n",
    "        return []\n",
    "\n",
    "    if forbidden_core_set is None:\n",
    "        forbidden_core_set = set()\n",
    "\n",
    "    # 1) Get pronunciations for the core word\n",
    "    phones_list = pronouncing.phones_for_word(core.lower())\n",
    "    if not phones_list:\n",
    "        return []\n",
    "\n",
    "    phones = phones_list[0]\n",
    "\n",
    "    # 2) Get syllable count for the core word\n",
    "    try:\n",
    "        core_syllables = pronouncing.syllable_count(phones)\n",
    "    except Exception:\n",
    "        core_syllables = None\n",
    "\n",
    "    # 3) Get rhyme pattern and search for rhyming words\n",
    "    rhyme_pat = pronouncing.rhyming_part(phones)\n",
    "    candidates = pronouncing.search(rhyme_pat + \"$\")\n",
    "\n",
    "    # Fallback to simple rhymes() if search gives nothing\n",
    "    if not candidates:\n",
    "        candidates = pronouncing.rhymes(core.lower())\n",
    "\n",
    "    cleaned = []\n",
    "    for w in candidates:\n",
    "        lw_core = word_core_lower(w)\n",
    "\n",
    "        # skip if already in poem\n",
    "        if lw_core in forbidden_core_set:\n",
    "            continue\n",
    "\n",
    "        # optional: require same syllable count\n",
    "        if core_syllables is not None:\n",
    "            w_phones = pronouncing.phones_for_word(w.lower())\n",
    "            if not w_phones:\n",
    "                continue\n",
    "            if pronouncing.syllable_count(w_phones[0]) != core_syllables:\n",
    "                continue\n",
    "\n",
    "        cleaned.append(w)\n",
    "\n",
    "    # match capitalization pattern of original core\n",
    "    if core.istitle():\n",
    "        cleaned = [w.title() for w in cleaned]\n",
    "\n",
    "    # reattach punctuation\n",
    "    cleaned = [w + punct for w in cleaned]\n",
    "\n",
    "    random.shuffle(cleaned)\n",
    "    return cleaned[:max_distractors]\n",
    "\n",
    "\n",
    "# --------- main pipeline ---------\n",
    "def build_line_level_game_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Input df must have columns (your current setup):\n",
    "        - name       (author name)\n",
    "        - title      (poem title)\n",
    "        - poem_link\n",
    "        - first_line (using this as poem text for now; can switch to poem_text later)\n",
    "\n",
    "    Output: line-level dataframe with columns:\n",
    "        poem_slug, author_name, poem_title, poem_link,\n",
    "        line_index, line_text,\n",
    "        correct_last_word, choice_1..choice_6\n",
    "    \"\"\"\n",
    "    game_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        poem_text = row.get(\"first_line\")\n",
    "        if not isinstance(poem_text, str) or not poem_text.strip():\n",
    "            continue  # skip missing/empty\n",
    "\n",
    "        author_name = row.get(\"name\", \"\")\n",
    "        poem_title = row[\"title\"]\n",
    "        poem_link = row[\"poem_link\"]\n",
    "\n",
    "        poem_slug = slugify(f\"{author_name}-{poem_title}\")\n",
    "\n",
    "        # split into non-empty lines\n",
    "        lines = [ln for ln in poem_text.split(\"\\n\") if ln.strip()]\n",
    "\n",
    "        # ---- all word cores in this poem (forbidden for distractors) ----\n",
    "        forbidden_cores = set()\n",
    "        for ln in lines:\n",
    "            for tok in ln.split():\n",
    "                forbidden_cores.add(word_core_lower(tok))\n",
    "\n",
    "        for line_index, line in enumerate(lines):\n",
    "            tokens = line.split()\n",
    "            if not tokens:\n",
    "                continue\n",
    "\n",
    "            last_word_raw = tokens[-1]\n",
    "            core, punct = split_core_and_punct(last_word_raw)\n",
    "\n",
    "            # get up to 5 rhyming distractors\n",
    "            distractors = rhyme_distractors(\n",
    "                core,\n",
    "                punct,\n",
    "                forbidden_core_set=forbidden_cores,\n",
    "                max_distractors=5,\n",
    "            )\n",
    "\n",
    "            correct_last_word = last_word_raw  # keep original incl. punctuation\n",
    "            correct_core_l = word_core_lower(correct_last_word)\n",
    "\n",
    "            # ---------- HARD NO-DUPLICATE GUARD (core-based) ----------\n",
    "            unique_distractors = []\n",
    "            seen_cores = {correct_core_l}  # start with correct word's core\n",
    "\n",
    "            for d in distractors:\n",
    "                d_core_l = word_core_lower(d)\n",
    "                if d_core_l in seen_cores:\n",
    "                    continue\n",
    "                seen_cores.add(d_core_l)\n",
    "                unique_distractors.append(d)\n",
    "\n",
    "            distractors = unique_distractors\n",
    "            # ----------------------------------------------------------\n",
    "\n",
    "            options = [correct_last_word] + distractors\n",
    "\n",
    "            # if we don't get at least 2 options, skip this line\n",
    "            if len(options) < 2:\n",
    "                continue\n",
    "\n",
    "            random.shuffle(options)\n",
    "\n",
    "            # pad to exactly 6 options (1 correct + up to 5 distractors)\n",
    "            while len(options) < 6:\n",
    "                options.append(\"\")\n",
    "\n",
    "            game_rows.append({\n",
    "                \"poem_slug\": poem_slug,\n",
    "                \"author_name\": author_name,\n",
    "                \"poem_title\": poem_title,\n",
    "                \"poem_link\": poem_link,\n",
    "                \"line_index\": line_index,\n",
    "                \"line_text\": line,\n",
    "                \"correct_last_word\": correct_last_word,\n",
    "                \"choice_1\": options[0],\n",
    "                \"choice_2\": options[1],\n",
    "                \"choice_3\": options[2],\n",
    "                \"choice_4\": options[3],\n",
    "                \"choice_5\": options[4],\n",
    "                \"choice_6\": options[5],\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(game_rows)\n",
    "\n",
    "\n",
    "# --------- example usage ---------\n",
    "# df = pd.read_csv(\"poems_with_text.csv\")\n",
    "game_df = build_line_level_game_df(df)\n",
    "game_df.to_csv(\"poem_rhyme_game.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_line_level_game_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_words\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrhyming_words\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_line\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(get_rhymes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[42], line 18\u001b[0m, in \u001b[0;36mget_rhymes\u001b[0;34m(poem)\u001b[0m\n\u001b[1;32m     16\u001b[0m         rhymes \u001b[38;5;241m=\u001b[39m pronouncing\u001b[38;5;241m.\u001b[39mrhymes(word)\n\u001b[1;32m     17\u001b[0m         rhymes \u001b[38;5;241m=\u001b[39m [rhyme \u001b[38;5;28;01mfor\u001b[39;00m rhyme \u001b[38;5;129;01min\u001b[39;00m rhymes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rhyme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m         rhymes \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(rhymes, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     20\u001b[0m     rhyming_words\u001b[38;5;241m.\u001b[39mappend(rhymes) \n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(words)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/random.py:456\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    454\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    457\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m    458\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "df[['true_words', 'rhyming_words']] = df['first_line'].apply(get_rhymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\"tree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pronouncing\n",
    "import string\n",
    "\n",
    "def get_rhymes(poem):\n",
    "    lines = poem.split(\"\\n\")\n",
    "    words = [line.split() for line in lines]\n",
    "\n",
    "    last_words = [line[-1] for line in words if len(line) >= 1]\n",
    "\n",
    "    rhyming_words = []\n",
    "\n",
    "    for word in last_words:\n",
    "        word = word.strip()\n",
    "\n",
    "        # ---- 1) capture core word + trailing punctuation ----\n",
    "        # matches:   core=\"night\"   punct=\",\"  in \"night,\"\n",
    "        m = re.match(r\"^([A-Za-z']+)([^A-Za-z']*)$\", word)\n",
    "        if m:\n",
    "            core = m.group(1)\n",
    "            punct = m.group(2)\n",
    "        else:\n",
    "            core = word\n",
    "            punct = \"\"\n",
    "\n",
    "        # ---- 2) get rhymes for core word ----\n",
    "        if core.istitle():\n",
    "            rhymes = pronouncing.rhymes(core.lower())\n",
    "            rhymes = [rhyme.title() for rhyme in rhymes if len(rhyme) > 2]\n",
    "        else:\n",
    "            rhymes = pronouncing.rhymes(core.lower())\n",
    "            rhymes = [rhyme for rhyme in rhymes if len(rhyme) > 2]\n",
    "\n",
    "        if len(rhymes) >= 5:\n",
    "            rhymes = random.sample(rhymes, 5)\n",
    "\n",
    "        # ---- 3) reattach punctuation to each rhyme ----\n",
    "        rhymes_with_punct = [r + punct for r in rhymes]\n",
    "\n",
    "        rhyming_words.append(rhymes_with_punct)\n",
    "\n",
    "    return last_words, rhyming_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhymes(poem):\n",
    "    lines = poem.split(\"\\n\")\n",
    "    words = [line.split() for line in lines]\n",
    "    #for line in words:\n",
    "     #   print(line[-1])\n",
    "\n",
    "    \n",
    "    last_words = [line[-1] for line in words if len(line) >= 1]\n",
    "    print(last_words)\n",
    "\n",
    "    rhyming_words = []\n",
    "    for word in last_words:\n",
    "        word = word.strip()\n",
    "        if word.istitle():\n",
    "            rhymes = pronouncing.rhymes(word) \n",
    "            rhymes = [rhyme.title() for rhyme in rhymes if len(rhyme) > 2]\n",
    "            if len(rhymes) >= 5:\n",
    "                rhymes = random.sample(rhymes, 5)\n",
    "        else:\n",
    "            rhymes = pronouncing.rhymes(word)\n",
    "            rhymes = [rhyme for rhyme in rhymes if len(rhyme) > 2]\n",
    "            if len(rhymes) >= 5:\n",
    "                rhymes = random.sample(rhymes, 5)\n",
    "\n",
    "        rhyming_words.append(rhymes) \n",
    "\n",
    "\n",
    "   # print(words)\n",
    "    #print(last_words)\n",
    "    #print(rhyming_words)\n",
    "    return last_words, rhyming_words\n",
    "\n",
    "    \n",
    "\n",
    "    #return last_words, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['In', 'sixth', 'grade', 'Mrs.', 'Walker'], ['slapped', 'the', 'back']]\n",
      "['Walker', 'back']\n",
      "[['Walker', 'Talker', 'Stalker', 'Hawker', 'Chalker'], ['vanvlack', 'crack', 'brack', 'haque', 'hacke']]\n"
     ]
    }
   ],
   "source": [
    "get_rhymes(\"In sixth grade Mrs. Walker\\nslapped the back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diming', 'liming', 'priming', 'rhyming', 'timing']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouncing.rhymes(\"climbing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
